{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.training_kits import stdout_to_tqdm, load_pretrained_state\n",
    "\n",
    "from data import get_dataset\n",
    "from config.config import DATASET, config_dict\n",
    "from utils.visualization_tools import draw_heatmaps, draw_region_maps, draw_point, draw_bbox, draw_text,draw_centermap\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "config_dict['batch_size'] = 1\n",
    "config_dict['workers'] = 1\n",
    "\n",
    "new_size = config_dict[\"image_size\"][0]\n",
    "def draw_region_bbox(img, xywhc, color=(0, 0, 255)):\n",
    "    cx, cy, w, h = xywhc[:4]\n",
    "    x1, y1, x2, y2 = cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2\n",
    "    x1 = int(max(0, x1))\n",
    "    y1 = int(max(0, y1))\n",
    "    x2 = int(min(x2, new_size))\n",
    "    y2 = int(min(y2, new_size))\n",
    "    img = draw_bbox(img, x1, y1, x2, y2, color=color)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1、用于可视化用SimDR检测关键点的手部检测\n",
    "from models.center_simDR import LiteHourglassNet as Network\n",
    "from utils.CenterSimDRParser import ResultParser\n",
    "\n",
    "img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = \\\n",
    "None, None, None, None, None, None, None, None\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name=''):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(set_type='test')\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.writer = SummaryWriter(log_dir='jupyter_log/'+ exp_name)\n",
    "        self.parser = ResultParser()\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, meta in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "                img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = meta\n",
    "                \n",
    "                if not self.ground_truth:\n",
    "                    pred_centermap, pred_x, pred_y = self.model(img.to(self.device))\n",
    "                else:\n",
    "                    pred_centermap, pred_x, pred_y = centermap, target_x, target_y\n",
    "         \n",
    "                # 结果解析，得到原图关键点和边界框\n",
    "                pred_kpts, pred_bboxes = self.parser.parse(pred_centermap, pred_x, pred_y)\n",
    "                ap50, ap = self.parser.evaluate_ap(pred_bboxes, bbox)\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    out_centermap = draw_centermap(centermap)\n",
    "                    out_centermap = [torch.tensor(out, dtype=torch.uint8) for out in out_centermap]\n",
    "                    imgs = torch.stack(out_centermap, dim=0)\n",
    "                    self.writer.add_image('centermap', imgs, i, dataformats='NHWC')\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    batch_xywh = pred_bboxes[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "\n",
    "                    for image, kpts, xywh in zip(img, pred_kpts, batch_xywh):  \n",
    "                    # for image, kpts, xywh in zip(img, gt_kpts, batch_xywh):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        \n",
    "                        # kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "                        kpts = kpts[0].detach().cpu().numpy()\n",
    "                        # print(f\"{image.shape=}\")\n",
    "                        print(f\"{bbox=}\")\n",
    "                        print(f\"{xywh=}\")\n",
    "                        print(f\"{i=} ：{kpts=}\")\n",
    "                        print(F\"{i=} ：{gt_kpts[0, 0]=}\")\n",
    "                        print('*'* 100)\n",
    "                        \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "                        image_drawn = draw_region_bbox(image_drawn, xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn, dtype=torch.uint8)], dim=0)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2、用于可视化用热图检测关键点的手部检测\n",
    "from models.hourglass_SA import HourglassNet_SA as Network\n",
    "from utils.evaluation import evaluate_pck, evaluate_ap, get_coordinates_from_heatmap\n",
    "from utils.CenterSimDRParser import ResultParser\n",
    "\n",
    "\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name='cs'):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(set_type='test')\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.result_parser = ResultParser()\n",
    "        self.writer = SummaryWriter(log_dir= 'jupyter_log/' + exp_name)\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True, show_cd=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, (img, target_x, target_y, target_weight, kpts_hm, bbox, gt_kpts) in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "\n",
    "                if show_cd:  # 显示循环检测的效果\n",
    "                    img, target_x, target_y, kpts_hm, gt_kpts = self.dataset.generate_cd_gt(img, gt_kpts, bbox, target_weight)\n",
    "                    bbox = torch.tensor([[[img.shape[3] / 2, img.shape[2] / 2,\n",
    "                                     img.shape[3], img.shape[2]]]], device=bbox.device)\n",
    "  \n",
    "\n",
    "                target = kpts_hm\n",
    "                region = target[:, :3]\n",
    "                hm_kpts = target[:, 3:].to(self.device)\n",
    "\n",
    "                if not self.ground_truth:\n",
    "                    hms_list, pred_x, pred_y  = self.model(img.to(self.device))\n",
    "                    hm_kpts = hms_list[-1][:, 3:]\n",
    "                    region = hms_list[-1][:, :3]\n",
    "                \n",
    "                pck += evaluate_pck(hm_kpts, target[:, 3:], bbox, thr=0.2).item()\n",
    "                print(f\"{pck=}\")\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    draw_region_maps(region)\n",
    "                    draw_heatmaps(hm_kpts)\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    # batch_xywh = cs_from_region_map(batch_region_maps=region, k=1, thr=0.1)\n",
    "                    _, _, batch_xywh = evaluate_ap(region, bbox, k=10, conf_thr=0.1)\n",
    "                    # print(f\"{batch_xywh=}\")\n",
    "                    batch_xywh = batch_xywh[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "                        \n",
    "                    # ! 因为现在是单手，所以特殊处理一下\n",
    "                    bbox = bbox[0]\n",
    "                    gt_kpts = gt_kpts[:, 0]\n",
    "\n",
    "                    first_time_kpt = self.result_parser.get_pred_kpt(hm_kpts)\n",
    "                    first_time_kpt[:, :, :2] *= torch.tensor([4, 4], device=first_time_kpt.device)\n",
    "                    pred_bboxes = self.result_parser.get_pred_bbox(region)\n",
    "                    second_time_kpt = self.result_parser.get_group_keypoints(self.model, img, pred_bboxes, hm_kpts)\n",
    "\n",
    "                    for image, gk, ftk, stk, xywh, gt_xywh in zip(img, gt_kpts,\n",
    "                                                          first_time_kpt, second_time_kpt,\n",
    "                                                          batch_xywh, bbox):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_gt = draw_results(image, gk, gt_xywh, gt_xywh)\n",
    "                        image_drawn1 = draw_results(image, ftk, xywh, gt_xywh)\n",
    "                        image_drawn2 = draw_results(image, stk, xywh, gt_xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn1, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_gt, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn1, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn2, dtype=torch.uint8),\n",
    "                                        ], dim=0)\n",
    "                    # img_grid = vutils.make_grid(imgs, normalize=True, scale_each=True, nrow=2)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "\n",
    "def draw_results(image, kpts, xywh, gt_xywh):\n",
    "    \"\"\"在图片上画出预测关键点、预测框和真值框\n",
    "\n",
    "    Args:\n",
    "        image (numpy): (h, w, c)\n",
    "        kpts (tensor): (1, n_joints, 3)\n",
    "        xywh (tensor): (5,) (cx, cy, w, h, score)\n",
    "        gt_xywh (tensor): (4,) (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "    image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "    image_drawn = draw_region_bbox(image_drawn, xywh, (255, 0, 0))\n",
    "    image_drawn = draw_region_bbox(image_drawn, gt_xywh, (0, 255, 0))\n",
    "    return image_drawn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "sample number of testing dataset:  13024\n",
      "done!\n",
      "loading state dict...\n",
      "save_dict.keys()=dict_keys(['epoch', 'lr', 'loss', 'mPCK', 'ap', 'state_dict', 'optimizer', 'config'])\n",
      "done! is_match=True\n",
      "pck=1.0\n",
      "pck=1.9047619104385376\n",
      "pck=2.9047619104385376\n",
      "pck=3.9047619104385376\n",
      "pck=4.904761910438538\n",
      "pck=5.809523820877075\n",
      "pck=6.809523820877075\n",
      "pck=7.809523820877075\n",
      "pck=7.809523820877075\n",
      "pck=8.714285731315613\n",
      "pck=9.61904764175415\n",
      "pck=9.666666690260172\n",
      "pck=10.476190511137247\n",
      "pck=11.380952421575785\n",
      "pck=12.238095287233591\n",
      "pck=13.19047624245286\n",
      "pck=14.19047624245286\n",
      "pck=15.19047624245286\n",
      "pck=16.19047624245286\n",
      "pck=17.19047624245286\n",
      "pck=17.19047624245286\n",
      "pck=17.19047624245286\n",
      "pck=17.19047624245286\n",
      "pck=18.19047624245286\n",
      "pck=19.19047624245286\n",
      "pck=19.19047624245286\n",
      "pck=20.19047624245286\n",
      "pck=21.14285719767213\n",
      "pck=22.047619108110666\n",
      "pck=22.333333406597376\n",
      "pck=22.333333406597376\n",
      "pck=23.333333406597376\n",
      "pck=24.238095317035913\n",
      "pck=24.571428660303354\n",
      "pck=24.666666757315397\n",
      "pck=24.666666757315397\n",
      "pck=24.71428580582142\n",
      "pck=25.190476283431053\n",
      "pck=26.09523819386959\n",
      "pck=27.00000010430813\n",
      "pck=28.00000010430813\n",
      "pck=28.00000010430813\n",
      "pck=28.571428701281548\n",
      "pck=29.571428701281548\n",
      "pck=30.571428701281548\n",
      "pck=31.571428701281548\n",
      "pck=32.57142870128155\n",
      "pck=33.57142870128155\n",
      "pck=34.57142870128155\n",
      "pck=34.57142870128155\n",
      "pck=35.57142870128155\n",
      "pck=36.57142870128155\n",
      "pck=36.809523940086365\n",
      "pck=37.809523940086365\n",
      "pck=38.7142858505249\n",
      "pck=38.7142858505249\n",
      "pck=39.7142858505249\n",
      "pck=40.61904776096344\n",
      "pck=40.61904776096344\n",
      "pck=40.61904776096344\n",
      "pck=40.66666680946946\n",
      "pck=41.66666680946946\n",
      "pck=42.66666680946946\n",
      "pck=43.66666680946946\n",
      "pck=43.66666680946946\n",
      "pck=43.66666680946946\n",
      "pck=44.571428719908\n",
      "pck=45.428571585565805\n",
      "pck=46.428571585565805\n",
      "pck=47.428571585565805\n",
      "pck=48.428571585565805\n",
      "pck=48.66666682437062\n",
      "pck=49.66666682437062\n",
      "pck=50.66666682437062\n",
      "pck=51.66666682437062\n",
      "pck=52.66666682437062\n",
      "pck=52.66666682437062\n",
      "pck=52.66666682437062\n",
      "pck=52.66666682437062\n",
      "pck=53.66666682437062\n",
      "pck=54.66666682437062\n",
      "pck=55.66666682437062\n",
      "pck=56.66666682437062\n",
      "pck=56.66666682437062\n",
      "pck=57.66666682437062\n",
      "pck=57.66666682437062\n",
      "pck=57.66666682437062\n",
      "pck=58.66666682437062\n",
      "pck=59.66666682437062\n",
      "pck=59.66666682437062\n",
      "pck=60.52380969002843\n",
      "pck=61.23809542134404\n",
      "pck=62.09523828700185\n",
      "pck=62.09523828700185\n",
      "pck=62.09523828700185\n",
      "pck=62.09523828700185\n",
      "pck=62.714285928756\n",
      "pck=63.619047839194536\n",
      "pck=64.61904783919454\n",
      "pck=65.52380974963307\n",
      "pck=66.14285739138722\n",
      "n_img=100\n",
      "pck=0.6548797761523487\n"
     ]
    }
   ],
   "source": [
    "# path = \"./checkpoint/MSRB-D-DW-PELEE/1HG-ME-att-c256/2021-12-27/0.981_PCK_47epoch.pt\"\n",
    "path = \"checkpoint/final_ME-att/ls/1HG-ME-att-c128-h4-k2-o64-gtbbox-no_augment/2022-03-10/72.566_AP_52epoch.pt\"\n",
    "t = TestPreds(checkpoint=path, is_cuda=False, ground_truth=False, exp_name='gtbbox/r3')\n",
    "t.test(n_img=100, show_hms=False, show_kpts=True, show_cd=False)\n",
    "# tensorboard --samples_per_plugin scalars=100,images=100 --logdir \"./jupyter_log/r_gtbbox/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[    0.65047,    0.019208,     0.41188],\n",
       "        [    0.88008,     0.91811,     0.82871],\n",
       "        [    0.36613,      0.6997,    0.056114],\n",
       "        [    0.39086,     0.24489,     0.30793]],\n",
       "\n",
       "       [[   0.046529,     0.69157,    0.043093],\n",
       "        [    0.17521,     0.13193,     0.95549],\n",
       "        [    0.70705,     0.86237,    0.061276],\n",
       "        [     0.8503,     0.42167,     0.97655]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = np.random.rand(2, 4, 3)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.36613,    0.019208,    0.056114],\n",
       "       [   0.046529,     0.13193,    0.043093]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(j, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf3c481f90fadfbf722cb3b828ed9b00fdd65b6593be65f64d94912de1f7f65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('TorchCV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
