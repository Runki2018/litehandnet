{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.evaluation import evaluate_pck, evaluate_ap, get_coordinates_from_heatmap\n",
    "from utils.training_kits import stdout_to_tqdm, load_pretrained_state\n",
    "\n",
    "from models.hourglass_SA import HourglassNet_SA as Network\n",
    "from data import get_dataset\n",
    "from config.config import DATASET, config_dict\n",
    "from utils.visualization_tools import draw_heatmaps, draw_region_maps, draw_point, draw_bbox, draw_text\n",
    "from time import sleep\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = config_dict[\"image_size\"][0]\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(set_type='test')\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.writer = SummaryWriter(log_dir='jupyter_log')\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, (img, hm_target, hm_weight, label, bbox) in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                # print(f\"{bbox=}\")\n",
    "                # print(f\"{bbox.shape=}\")\n",
    "\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "\n",
    "                target = hm_target[-1]\n",
    "                region = target[:, :3]\n",
    "                hm_kpts = target[:, 3:].to(self.device)\n",
    "                mask = hm_kpts[:, 0]\n",
    "\n",
    "                if not self.ground_truth:\n",
    "                    hms_list = self.model(img.to(self.device))  # [22, 22, 22, 44, 88]\n",
    "                    hm_kpts = hms_list[-1][:, 3:]\n",
    "                    region = hms_list[-1][:, :3]\n",
    "                    \n",
    "                pck += evaluate_pck(hm_kpts, target[:, 3:], bbox, thr=0.2).item()\n",
    "                print(f\"{pck=}\")\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    draw_region_maps(region)\n",
    "                    draw_heatmaps(mask)\n",
    "                    draw_heatmaps(hm_kpts)\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    # batch_xywh = cs_from_region_map(batch_region_maps=region, k=1, thr=0.1)\n",
    "                    _, _, batch_xywh = evaluate_ap(region, bbox, k=10, conf_thr=0.1)\n",
    "                    # print(f\"{batch_xywh=}\")\n",
    "                    batch_xywh = batch_xywh[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "\n",
    "                    batch_kpts, _ = get_coordinates_from_heatmap(hm_kpts)\n",
    "                    # batch_kpts = self.get_coordinates(hm_kpts[:, 4:])\n",
    "                    # print(f\"{batch_kpts.shape=}\")\n",
    "\n",
    "                    heatmaps_size = hm_kpts.shape[-1]\n",
    "                    batch_kpts[..., :2] = batch_kpts[..., :2] * new_size / heatmaps_size  # scale to original size\n",
    "\n",
    "\n",
    "                    for image, kpts, xywh in zip(img, batch_kpts, batch_xywh):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        \n",
    "                        kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "                        print(f\"{image.shape=}\")\n",
    "                        print(f\"{kpts.shape=}\")\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "                        image_drawn = self.draw_region_bbox(image_drawn, xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn, dtype=torch.uint8)], dim=0)\n",
    "                    # img_grid = vutils.make_grid(imgs, normalize=True, scale_each=True, nrow=2)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_region_bbox(img, xywhc):\n",
    "        cx, cy, w, h = xywhc[:4]\n",
    "        x1, y1, x2, y2 = cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2\n",
    "        x1 = int(max(0, x1))\n",
    "        y1 = int(max(0, y1))\n",
    "        x2 = int(min(x2, new_size))\n",
    "        y2 = int(min(y2, new_size))\n",
    "        img = draw_bbox(img, x1, y1, x2, y2)\n",
    "        return img\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_coordinates(batch_kpts_hm):\n",
    "        # (batch, n_joints, h, w)\n",
    "        batch, n_joints, h, w = batch_kpts_hm.shape\n",
    "        top_val, top_idx = torch.topk(batch_kpts_hm.reshape((batch, n_joints, -1)), k=1)\n",
    "\n",
    "        batch_kpts = torch.zeros((batch, n_joints, 3))\n",
    "        batch_kpts[..., 0] = (top_idx % w).reshape((batch, n_joints))  # x\n",
    "        batch_kpts[..., 1] = (top_idx // w).reshape((batch, n_joints))  # y\n",
    "        batch_kpts[..., 2] = top_val.reshape((batch, n_joints))  # c: score\n",
    "\n",
    "        return batch_kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "sample number of testing dataset:  13024\n",
      "done!\n",
      "loading state dict...\n",
      "save_dict.keys()=dict_keys(['epoch', 'lr', 'loss', 'mPCK', 'ap', 'state_dict', 'optimizer', 'config'])\n",
      "done! is_match=True\n",
      "pck=0.959821430966258\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=1.9523809552192688\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=2.9434523843228817\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=3.900297624990344\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=4.858630960807204\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=5.848214294761419\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=6.776785724796355\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=7.775297629646957\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=8.751488107256591\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=9.741071441210806\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=10.66964287403971\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=11.607142876833677\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=12.602678591385484\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=13.559523832052946\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=14.537202404811978\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=15.498511930927634\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=16.48809526488185\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=17.46577383764088\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=18.462797647342086\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=19.462797647342086\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "pck=20.462797647342086\n",
      "image.shape=(256, 256, 3)\n",
      "kpts.shape=(21, 2)\n",
      "n_img=20\n",
      "pck=0.9744189355877184\n"
     ]
    }
   ],
   "source": [
    "path = \"./checkpoint/MSRB-D-DW-PELEE/1HG-ME-att-c256/2021-12-27/0.981_PCK_47epoch.pt\"\n",
    "t = TestPreds(checkpoint=path, is_cuda=False, ground_truth=False)\n",
    "t.test(n_img=20, show_hms=False, show_kpts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf3c481f90fadfbf722cb3b828ed9b00fdd65b6593be65f64d94912de1f7f65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('TorchCV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
