{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.training_kits import stdout_to_tqdm, load_pretrained_state\n",
    "\n",
    "from data import get_dataset\n",
    "from config.config import DATASET, config_dict\n",
    "from utils.visualization_tools import draw_heatmaps, draw_region_maps, draw_point, draw_bbox, draw_text,draw_centermap\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "config_dict['batch_size'] = 1\n",
    "config_dict['workers'] = 1\n",
    "\n",
    "new_size = config_dict[\"image_size\"][0]\n",
    "def draw_region_bbox(img, xywhc, color=(0, 0, 255)):\n",
    "    cx, cy, w, h = xywhc[:4]\n",
    "    x1, y1, x2, y2 = cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2\n",
    "    x1 = int(max(0, x1))\n",
    "    y1 = int(max(0, y1))\n",
    "    x2 = int(min(x2, new_size))\n",
    "    y2 = int(min(y2, new_size))\n",
    "    img = draw_bbox(img, x1, y1, x2, y2, color=color)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1、用于可视化用SimDR检测关键点的手部检测\n",
    "from models.center_simDR import LiteHourglassNet as Network\n",
    "from utils.CenterSimDRParser import ResultParser\n",
    "\n",
    "img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = \\\n",
    "None, None, None, None, None, None, None, None\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name=''):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(set_type='test')\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.writer = SummaryWriter(log_dir='jupyter_log/'+ exp_name)\n",
    "        self.parser = ResultParser()\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, meta in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "                img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = meta\n",
    "                \n",
    "                if not self.ground_truth:\n",
    "                    pred_centermap, pred_x, pred_y = self.model(img.to(self.device))\n",
    "                else:\n",
    "                    pred_centermap, pred_x, pred_y = centermap, target_x, target_y\n",
    "         \n",
    "                # 结果解析，得到原图关键点和边界框\n",
    "                pred_kpts, pred_bboxes = self.parser.parse(pred_centermap, pred_x, pred_y)\n",
    "                ap50, ap = self.parser.evaluate_ap(pred_bboxes, bbox)\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    out_centermap = draw_centermap(centermap)\n",
    "                    out_centermap = [torch.tensor(out, dtype=torch.uint8) for out in out_centermap]\n",
    "                    imgs = torch.stack(out_centermap, dim=0)\n",
    "                    self.writer.add_image('centermap', imgs, i, dataformats='NHWC')\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    batch_xywh = pred_bboxes[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "\n",
    "                    for image, kpts, xywh in zip(img, pred_kpts, batch_xywh):  \n",
    "                    # for image, kpts, xywh in zip(img, gt_kpts, batch_xywh):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        \n",
    "                        # kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "                        kpts = kpts[0].detach().cpu().numpy()\n",
    "                        # print(f\"{image.shape=}\")\n",
    "                        print(f\"{bbox=}\")\n",
    "                        print(f\"{xywh=}\")\n",
    "                        print(f\"{i=} ：{kpts=}\")\n",
    "                        print(F\"{i=} ：{gt_kpts[0, 0]=}\")\n",
    "                        print('*'* 100)\n",
    "                        \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "                        image_drawn = draw_region_bbox(image_drawn, xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn, dtype=torch.uint8)], dim=0)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2、用于可视化用热图检测关键点的手部检测\n",
    "from models.hourglass_SA import HourglassNet_SA as Network\n",
    "from utils.evaluation import evaluate_pck, evaluate_ap, get_coordinates_from_heatmap\n",
    "from utils.CenterSimDRParser import ResultParser\n",
    "\n",
    "\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name='cs'):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(set_type='test')\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.result_parser = ResultParser()\n",
    "        self.writer = SummaryWriter(log_dir= 'jupyter_log/' + exp_name)\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True, show_cd=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, (img, target_x, target_y, target_weight, kpts_hm, bbox, gt_kpts) in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "\n",
    "                if show_cd:  # 显示循环检测的效果\n",
    "                    img, target_x, target_y, kpts_hm, gt_kpts = self.dataset.generate_cd_gt(img, gt_kpts, bbox, target_weight)\n",
    "                    bbox = torch.tensor([[[img.shape[3] / 2, img.shape[2] / 2,\n",
    "                                     img.shape[3], img.shape[2]]]], device=bbox.device)\n",
    "  \n",
    "\n",
    "                target = kpts_hm\n",
    "                region = target[:, :3]\n",
    "                hm_kpts = target[:, 3:].to(self.device)\n",
    "                mask = hm_kpts[:, 0]\n",
    "\n",
    "                if not self.ground_truth:\n",
    "                    hms_list, pred_x, pred_y  = self.model(img.to(self.device))\n",
    "                    hm_kpts = hms_list[-1][:, 3:]\n",
    "                    region = hms_list[-1][:, :3]\n",
    "                \n",
    "                pck += evaluate_pck(hm_kpts, target[:, 3:], bbox, thr=0.2).item()\n",
    "                print(f\"{pck=}\")\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    draw_region_maps(region)\n",
    "                    draw_heatmaps(mask)\n",
    "                    draw_heatmaps(hm_kpts)\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    # batch_xywh = cs_from_region_map(batch_region_maps=region, k=1, thr=0.1)\n",
    "                    _, _, batch_xywh = evaluate_ap(region, bbox, k=10, conf_thr=0.1)\n",
    "                    # print(f\"{batch_xywh=}\")\n",
    "                    batch_xywh = batch_xywh[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "                        \n",
    "                    # ! 因为现在是单手，所以特殊处理一下\n",
    "                    bbox = bbox[0]\n",
    "                    gt_kpts = gt_kpts[:, 0]\n",
    "\n",
    "                    first_time_kpt = self.result_parser.get_pred_kpt(hm_kpts)\n",
    "                    first_time_kpt[:, :, :2] *= torch.tensor([4, 4], device=first_time_kpt.device)\n",
    "                    pred_bboxes = self.result_parser.get_pred_bbox(region)\n",
    "                    second_time_kpt = self.result_parser.get_group_keypoints(self.model, img, pred_bboxes, hm_kpts)\n",
    "\n",
    "                    for image, gk, ftk, stk, xywh, gt_xywh in zip(img, gt_kpts,\n",
    "                                                          first_time_kpt, second_time_kpt,\n",
    "                                                          batch_xywh, bbox):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_gt = draw_results(image, gk, gt_xywh, gt_xywh)\n",
    "                        image_drawn1 = draw_results(image, ftk, xywh, gt_xywh)\n",
    "                        image_drawn2 = draw_results(image, stk, xywh, gt_xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn1, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_gt, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn1, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn2, dtype=torch.uint8),\n",
    "                                        ], dim=0)\n",
    "                    # img_grid = vutils.make_grid(imgs, normalize=True, scale_each=True, nrow=2)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "\n",
    "def draw_results(image, kpts, xywh, gt_xywh):\n",
    "    \"\"\"在图片上画出预测关键点、预测框和真值框\n",
    "\n",
    "    Args:\n",
    "        image (numpy): (h, w, c)\n",
    "        kpts (tensor): (1, n_joints, 3)\n",
    "        xywh (tensor): (5,) (cx, cy, w, h, score)\n",
    "        gt_xywh (tensor): (4,) (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "    image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "    image_drawn = draw_region_bbox(image_drawn, xywh, (255, 0, 0))\n",
    "    image_drawn = draw_region_bbox(image_drawn, gt_xywh, (0, 255, 0))\n",
    "    return image_drawn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "sample number of testing dataset:  266\n",
      "done!\n",
      "loading state dict...\n",
      "save_dict.keys()=dict_keys(['epoch', 'lr', 'loss', 'mPCK', 'ap', 'state_dict', 'optimizer', 'config'])\n",
      "done! is_match=True\n",
      "pck=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/data/Code/stage-network/utils/CenterSimDRParser.py:349: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  size = H // self.cd_reduction, W // self.cd_reduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pck=1.9523809552192688\n",
      "pck=2.952380955219269\n",
      "pck=3.952380955219269\n",
      "pck=4.952380955219269\n",
      "pck=5.952380955219269\n",
      "pck=6.952380955219269\n",
      "pck=7.904761910438538\n",
      "pck=8.904761910438538\n",
      "pck=9.904761910438538\n",
      "pck=10.904761910438538\n",
      "pck=11.904761910438538\n",
      "pck=12.904761910438538\n",
      "pck=13.28571429848671\n",
      "pck=14.28571429848671\n",
      "pck=15.28571429848671\n",
      "pck=16.190476208925247\n",
      "pck=17.190476208925247\n",
      "pck=18.190476208925247\n",
      "pck=19.190476208925247\n",
      "pck=20.190476208925247\n",
      "pck=21.190476208925247\n",
      "pck=22.190476208925247\n",
      "pck=23.095238119363785\n",
      "pck=24.095238119363785\n",
      "pck=25.000000029802322\n",
      "pck=26.000000029802322\n",
      "pck=27.000000029802322\n",
      "pck=27.85714289546013\n",
      "pck=28.85714289546013\n",
      "pck=29.85714289546013\n",
      "pck=30.52380958199501\n",
      "pck=31.52380958199501\n",
      "pck=32.52380958199501\n",
      "pck=33.52380958199501\n",
      "pck=34.47619053721428\n",
      "pck=35.47619053721428\n",
      "pck=36.47619053721428\n",
      "pck=37.47619053721428\n",
      "pck=38.47619053721428\n",
      "pck=39.42857149243355\n",
      "pck=40.333333402872086\n",
      "pck=41.333333402872086\n",
      "pck=42.333333402872086\n",
      "pck=43.333333402872086\n",
      "pck=44.333333402872086\n",
      "pck=45.333333402872086\n",
      "pck=46.333333402872086\n",
      "pck=47.333333402872086\n",
      "pck=48.333333402872086\n",
      "pck=49.333333402872086\n",
      "pck=50.333333402872086\n",
      "pck=51.333333402872086\n",
      "pck=52.333333402872086\n",
      "pck=53.285714358091354\n",
      "pck=54.23809531331062\n",
      "pck=55.23809531331062\n",
      "pck=56.23809531331062\n",
      "pck=57.23809531331062\n",
      "pck=58.23809531331062\n",
      "pck=59.23809531331062\n",
      "pck=60.14285722374916\n",
      "pck=61.14285722374916\n",
      "pck=62.09523817896843\n",
      "pck=63.0476191341877\n",
      "pck=64.0476191341877\n",
      "pck=65.0476191341877\n",
      "pck=66.00000008940697\n",
      "pck=67.00000008940697\n",
      "pck=68.00000008940697\n",
      "pck=69.00000008940697\n",
      "pck=70.00000008940697\n",
      "pck=71.00000008940697\n",
      "pck=71.95238104462624\n",
      "pck=72.95238104462624\n",
      "pck=73.85714295506477\n",
      "pck=74.85714295506477\n",
      "pck=75.85714295506477\n",
      "pck=76.85714295506477\n",
      "pck=77.80952391028404\n",
      "pck=78.80952391028404\n",
      "pck=79.80952391028404\n",
      "pck=80.80952391028404\n",
      "pck=81.80952391028404\n",
      "pck=82.80952391028404\n",
      "pck=83.80952391028404\n",
      "pck=84.80952391028404\n",
      "pck=85.80952391028404\n",
      "pck=86.80952391028404\n",
      "pck=87.42857155203819\n",
      "pck=88.38095250725746\n",
      "pck=89.38095250725746\n",
      "pck=90.38095250725746\n",
      "pck=91.38095250725746\n",
      "pck=92.38095250725746\n",
      "pck=93.38095250725746\n",
      "pck=94.38095250725746\n",
      "pck=95.33333346247673\n",
      "pck=96.33333346247673\n",
      "pck=97.33333346247673\n",
      "pck=98.33333346247673\n",
      "n_img=100\n",
      "pck=0.9735973610146211\n"
     ]
    }
   ],
   "source": [
    "# path = \"./checkpoint/MSRB-D-DW-PELEE/1HG-ME-att-c256/2021-12-27/0.981_PCK_47epoch.pt\"\n",
    "path = \"./checkpoint/final_ME-att/ls/1HG-ME-att-c128-h4-k2-o64-ba15/2022-03-05/97.842_PCK_24epoch.pt\"\n",
    "t = TestPreds(checkpoint=path, is_cuda=False, ground_truth=False, exp_name='r_cd_large')\n",
    "t.test(n_img=100, show_hms=False, show_kpts=True, show_cd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf3c481f90fadfbf722cb3b828ed9b00fdd65b6593be65f64d94912de1f7f65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('TorchCV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
