{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.training_kits import stdout_to_tqdm, load_pretrained_state\n",
    "\n",
    "from data import get_dataset\n",
    "from config import get_config\n",
    "from utils.visualization_tools import draw_heatmaps, draw_region_maps, draw_point, draw_bbox, draw_text,draw_centermap\n",
    "\n",
    "cfg, DATASET = get_config(\"config/freihand/cfg_freihand_hg_ms_att.py\")\n",
    "cfg['batch_size'] = 1\n",
    "cfg['workers'] = 1\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "new_size = cfg[\"image_size\"][0]\n",
    "def draw_region_bbox(img, xywhc, color=(0, 0, 255)):\n",
    "    cx, cy, w, h = xywhc[:4]\n",
    "    x1, y1, x2, y2 = cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2\n",
    "    x1 = int(max(0, x1))\n",
    "    y1 = int(max(0, y1))\n",
    "    x2 = int(min(x2, new_size))\n",
    "    y2 = int(min(y2, new_size))\n",
    "    img = draw_bbox(img, x1, y1, x2, y2, color=color)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1、用于可视化用SimDR检测关键点的手部检测\n",
    "from models.center_simDR import LiteHourglassNet as Network\n",
    "from utils.result_parser import ResultParser\n",
    "\n",
    "img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = \\\n",
    "None, None, None, None, None, None, None, None\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name=''):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(set_type='test')\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.writer = SummaryWriter(log_dir='jupyter_log/'+ exp_name)\n",
    "        self.parser = ResultParser()\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, meta in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "                img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = meta\n",
    "                \n",
    "                if not self.ground_truth:\n",
    "                    pred_centermap, pred_x, pred_y = self.model(img.to(self.device))\n",
    "                else:\n",
    "                    pred_centermap, pred_x, pred_y = centermap, target_x, target_y\n",
    "         \n",
    "                # 结果解析，得到原图关键点和边界框\n",
    "                pred_kpts, pred_bboxes = self.parser.parse(pred_centermap, pred_x, pred_y)\n",
    "                ap50, ap = self.parser.evaluate_ap(pred_bboxes, bbox)\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    out_centermap = draw_centermap(centermap)\n",
    "                    out_centermap = [torch.tensor(out, dtype=torch.uint8) for out in out_centermap]\n",
    "                    imgs = torch.stack(out_centermap, dim=0)\n",
    "                    self.writer.add_image('centermap', imgs, i, dataformats='NHWC')\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    batch_xywh = pred_bboxes[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "\n",
    "                    for image, kpts, xywh in zip(img, pred_kpts, batch_xywh):  \n",
    "                    # for image, kpts, xywh in zip(img, gt_kpts, batch_xywh):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        \n",
    "                        # kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "                        kpts = kpts[0].detach().cpu().numpy()\n",
    "                        # print(f\"{image.shape=}\")\n",
    "                        print(f\"{bbox=}\")\n",
    "                        print(f\"{xywh=}\")\n",
    "                        print(f\"{i=} :{kpts=}\")\n",
    "                        print(F\"{i=} :{gt_kpts[0, 0]=}\")\n",
    "                        print('*'* 100)\n",
    "                        \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "                        image_drawn = draw_region_bbox(image_drawn, xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn, dtype=torch.uint8)], dim=0)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2、用于可视化用热图检测关键点的手部检测\n",
    "from models.pose_estimation.pose_hg_ms_att import MultiScaleAttentionHourglass as Network\n",
    "from utils.evaluation import evaluate_pck, evaluate_ap, get_coordinates_from_heatmap\n",
    "from utils.result_parser import ResultParser\n",
    "\n",
    "\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name='cs'):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(cfg, DATASET,\n",
    "                                                     is_train=False,\n",
    "                                                     distributed=False)\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network(cfg).to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.result_parser = ResultParser(cfg)\n",
    "        self.writer = SummaryWriter(log_dir= 'jupyter_log/' + exp_name)\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True, show_cd=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, (img, targets, target_weight, bbox, gt_kpts, target_x, target_y) in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "\n",
    "                if show_cd:  # 显示循环检测的效果\n",
    "                    img, targets, gt_kpts, target_x, target_y = self.dataset.generate_cd_gt(img, gt_kpts, bbox, target_weight)\n",
    "                    bbox = torch.tensor([[[img.shape[3] / 2, img.shape[2] / 2,\n",
    "                                     img.shape[3], img.shape[2]]]], device=bbox.device)\n",
    "\n",
    "                targets = targets[0]\n",
    "                region = targets[:, :3]\n",
    "                hm_kpts = targets[:, 3:].to(self.device)\n",
    "\n",
    "                if not self.ground_truth:\n",
    "                    hms_list, pred_x, pred_y  = self.model(img.to(self.device))\n",
    "                    hm_kpts = hms_list[-1][:, 3:]\n",
    "                    region = hms_list[-1][:, :3]\n",
    "                \n",
    "                pck += evaluate_pck(hm_kpts, targets[:, 3:], bbox, thr=0.2).item()\n",
    "                print(f\"{pck=}\")\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    draw_region_maps(region)\n",
    "                    draw_heatmaps(hm_kpts)\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    # batch_xywh = cs_from_region_map(batch_region_maps=region, k=1, thr=0.1)\n",
    "                    _, _, batch_xywh = evaluate_ap(region, bbox, new_size, k=10, iou_thr=0.3)\n",
    "                    # print(f\"{batch_xywh=}\")\n",
    "                    batch_xywh = batch_xywh[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "                        \n",
    "                    # ! 因为现在是单手，所以特殊处理一下\n",
    "                    bbox = bbox[0]\n",
    "                    gt_kpts = gt_kpts[:, 0]\n",
    "\n",
    "                    first_time_kpt = self.result_parser.get_pred_kpt(hm_kpts)\n",
    "                    first_time_kpt[:, :, :2] *= torch.tensor([4, 4], device=first_time_kpt.device)\n",
    "                    pred_bboxes = self.result_parser.get_pred_bbox(region)\n",
    "                    second_time_kpt = self.result_parser.get_group_keypoints(self.model, img, pred_bboxes, hm_kpts)\n",
    "\n",
    "                    for image, gk, ftk, stk, xywh, gt_xywh in zip(img, gt_kpts,\n",
    "                                                          first_time_kpt, second_time_kpt,\n",
    "                                                          batch_xywh, bbox):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_gt = draw_results(image, gk, gt_xywh, gt_xywh)\n",
    "                        image_drawn1 = draw_results(image, ftk, xywh, gt_xywh)\n",
    "                        image_drawn2 = draw_results(image, stk, xywh, gt_xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn1, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_gt, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn1, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn2, dtype=torch.uint8),\n",
    "                                        ], dim=0)\n",
    "                    # img_grid = vutils.make_grid(imgs, normalize=True, scale_each=True, nrow=2)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "\n",
    "def draw_results(image, kpts, xywh, gt_xywh):\n",
    "    \"\"\"在图片上画出预测关键点、预测框和真值框\n",
    "\n",
    "    Args:\n",
    "        image (numpy): (h, w, c)\n",
    "        kpts (tensor): (1, n_joints, 3)\n",
    "        xywh (tensor): (5,) (cx, cy, w, h, score)\n",
    "        gt_xywh (tensor): (4,) (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "    image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "    image_drawn = draw_region_bbox(image_drawn, xywh, (255, 0, 0))\n",
    "    image_drawn = draw_region_bbox(image_drawn, gt_xywh, (0, 255, 0))\n",
    "    return image_drawn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "sample number of testing dataset:  5\n",
      "done!\n",
      "loading state dict...\n",
      "save_dict.keys()=dict_keys(['epoch', 'lr', 'loss', 'mPCK', 'ap', 'state_dict', 'optimizer', 'config'])\n",
      "done! is_match=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8.927] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/root/data/Dataset/multiscaleimages/00120525.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.997] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/root/data/Dataset/multiscaleimages/00024296.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@9.000] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/root/data/Dataset/multiscaleimages/00079305.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/data/Code/stage-network/data/handset/FreihandDataset.py\", line 94, in __getitem__\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ncv2.error: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5868/906208509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"checkpoint/final_ME-att/ls/1HG-ME-att-c128-h4-k2-o64-gtbbox-no_augment/2022-03-10/72.566_AP_52epoch.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestPreds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ms_freihand/r1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_hms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_cd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# tensorboard --samples_per_plugin scalars=100,images=100 --logdir \"./jupyter_log/r_gtbbox/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5868/924297079.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, n_img, show_hms, show_kpts, show_cd)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_img\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mn_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# -1 整个数据集过一遍\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_kpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_img\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/data/Code/stage-network/data/handset/FreihandDataset.py\", line 94, in __getitem__\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\ncv2.error: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n\n"
     ]
    }
   ],
   "source": [
    "# path = \"./checkpoint/MSRB-D-DW-PELEE/1HG-ME-att-c256/2021-12-27/0.981_PCK_47epoch.pt\"\n",
    "path = \"checkpoint/final_ME-att/ls/1HG-ME-att-c128-h4-k2-o64-gtbbox-no_augment/2022-03-10/72.566_AP_52epoch.pt\"\n",
    "t = TestPreds(checkpoint=path, is_cuda=False, ground_truth=True, exp_name='ms_freihand/r1')\n",
    "t.test(n_img=300, show_hms=False, show_kpts=True, show_cd=False)\n",
    "# tensorboard --samples_per_plugin scalars=100,images=100 --logdir \"./jupyter_log/r_gtbbox/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cf3c481f90fadfbf722cb3b828ed9b00fdd65b6593be65f64d94912de1f7f65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('TorchCV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
