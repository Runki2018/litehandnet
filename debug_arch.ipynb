{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def show_macs_params(model, img_size=(256, 256), dummy_input=None):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    if dummy_input is None:\n",
    "        dummy_input = torch.randn(1, 3, img_size[0], img_size[1], dtype=torch.float)\n",
    "    dummy_input = dummy_input.to(device)\n",
    "    \n",
    "     # macs == FLOPS, GFLOPS == 1e12 * FLOPS\n",
    "    macs, params = profile(model, inputs=(dummy_input,), verbose=False) \n",
    "    print(f\"{model._get_name()}\\t\\t{macs=}\\t{params=}\")\n",
    "    print(\"FLOPs=\", str(macs/1e9) +'{}'.format(\"G\"), end='\\t')\n",
    "    print(\"params=\", str(params/1e6)+'{}'.format(\"M\"))\n",
    "    macs, params = clever_format([macs, params], \"%.3f\")\n",
    "    print(f\"{macs=}\\t{params=}\")\n",
    "\n",
    "\n",
    "def inference_speed(model, img_size=(256, 256), dummy_input=None):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    if dummy_input is None:\n",
    "        dummy_input = torch.randn(1, 3, img_size[0], img_size[1], dtype=torch.float)\n",
    "    dummy_input = dummy_input.to(device)\n",
    "\n",
    "    starter = torch.cuda.Event(enable_timing=True)\n",
    "    ender = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    repetitions = 1000\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        _ = model(dummy_input)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            _ = model(dummy_input)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    mean_fps = 1000. / mean_syn\n",
    "    print('Mean@ {mean_syn:.3f}ms Std@ {std_syn:.3f}ms FPS@ {mean_fps:.2f}'\\\n",
    "        .format(mean_syn=mean_syn, std_syn=std_syn, mean_fps=mean_fps))\n",
    "    # ! @n 中的n是什么意思？\n",
    "    # print(' * Mean@1 {mean_syn:.3f}ms Std@5 {std_syn:.3f}ms FPS@1 {mean_fps:.2f}'\\\n",
    "    #     .format(mean_syn=mean_syn, std_syn=std_syn, mean_fps=mean_fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试LiteHandNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'identity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5734/3765699574.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitehandnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mshow_macs_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/Code/stage-network/models/pose_estimation/liteHandNet/liteHandNet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         self.hgs = EncoderDecoder(num_stage, inp_dim, num_block,\n\u001b[0m\u001b[1;32m    218\u001b[0m                                   ca_type, reduction, activation) \n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/Code/stage-network/models/pose_estimation/liteHandNet/liteHandNet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_levels, inp_dim, num_blocks, ca_type, reduction, activation)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_levels\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             self.encoder.append(\n\u001b[0;32m---> 83\u001b[0;31m                 Residual(inp_dim, inp_dim, 2, num_blocks[i], reduction, activation))\n\u001b[0m\u001b[1;32m     84\u001b[0m             self.decoder.append(\n\u001b[1;32m     85\u001b[0m                 Residual(inp_dim, inp_dim, 1, num_blocks[i], reduction, activation))\n",
      "\u001b[0;32m~/data/Code/stage-network/models/pose_estimation/liteHandNet/liteHandNet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inp_dim, out_dim, stride, num_block, reduction, activation)\u001b[0m\n\u001b[1;32m     59\u001b[0m                  reduction=2, activation=nn.LeakyReLU):\n\u001b[1;32m     60\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         self.blocks = nn.Sequential(\n\u001b[1;32m     63\u001b[0m             *[BottleNeck(out_dim, reduction, activation) for _ in range(num_block)])\n",
      "\u001b[0;32m~/data/Code/stage-network/models/pose_estimation/liteHandNet/liteHandNet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inp_dim, out_dim, stride, activation)\u001b[0m\n\u001b[1;32m     43\u001b[0m             RepConv(inp_dim, out_dim, 3, stride, 1,\n\u001b[1;32m     44\u001b[0m                      activation=activation, inplace=True),\n\u001b[0;32m---> 45\u001b[0;31m             RepConv(inp_dim, out_dim, 3, 1, 1,\n\u001b[0m\u001b[1;32m     46\u001b[0m                      activation=None, identity=False)\n\u001b[1;32m     47\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'identity'"
     ]
    }
   ],
   "source": [
    "import addict\n",
    "from models import litehandnet\n",
    "cfg = dict(MODEL=dict(\n",
    "    num_stage=4,\n",
    "    num_stack=1,\n",
    "    msrb_ca='ca',  # 'ca' | 'se' | 'none'\n",
    "    rbu_ca='ca',  # 'ca' | 'se' | 'none'\n",
    "    input_channel=256,\n",
    "    output_channel=21,\n",
    "))\n",
    "\n",
    "cfg = addict.Dict(cfg)\n",
    "model = litehandnet(cfg)\n",
    "\n",
    "show_macs_params(model, img_size=(256, 256))\n",
    "inference_speed(model, img_size=(256, 256))\n",
    "y = model(torch.rand(1, 3, 256, 256, device=torch.device(0)))\n",
    "print(y.shape)\n",
    "\n",
    "# 推理模型\n",
    "model.deploy_model()\n",
    "show_macs_params(model, img_size=(256, 256))\n",
    "inference_speed(model, img_size=(256, 256))\n",
    "y = model(torch.rand(1, 3, 256, 256, device=torch.device(0)))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem\t\tmacs=272105472.0\tparams=44992.0\n",
      "FLOPs= 0.272105472G\tparams= 0.044992M\n",
      "macs='272.105M'\tparams='44.992K'\n",
      "Mean@ 1.073ms Std@ 0.158ms FPS@ 931.71\n",
      "\n",
      "Sequential\t\tmacs=53477376.0\tparams=13056.0\n",
      "FLOPs= 0.053477376G\tparams= 0.013056M\n",
      "macs='53.477M'\tparams='13.056K'\n",
      "Mean@ 0.202ms Std@ 0.061ms FPS@ 4941.16\n"
     ]
    }
   ],
   "source": [
    "from models.pose_estimation.liteHandNet.repblocks import RepConv\n",
    "from models.pose_estimation.liteHandNet.common import SEBlock, ChannelAttension, channel_shuffle\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "        mid_channel = max(channel // 4, 32)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            RepConv(3, mid_channel, 3, 2, 1),\n",
    "            RepConv(mid_channel, mid_channel, 3, 1, 1, groups=mid_channel)\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            RepConv(mid_channel, mid_channel, 1, 1, 0),\n",
    "            RepConv(mid_channel, mid_channel, 3, 2, 1,\n",
    "                    groups=mid_channel, activation=None),\n",
    "            RepConv(mid_channel, mid_channel, 1, 1, 0),\n",
    "        )\n",
    "        self.branch2 = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
    "        self.conv2 = RepConv(2*mid_channel, channel, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        b1 = self.branch1(out)\n",
    "        b2 = self.branch2(out)\n",
    "        out = self.conv2(torch.cat([b1, b2], dim=1))\n",
    "        return out\n",
    "\n",
    "Stem4x4 = nn.Sequential(\n",
    "    nn.Conv2d(3, 256, 4, 4),\n",
    "    nn.BatchNorm2d(256)\n",
    ")\n",
    "\n",
    "stem1 = Stem(256)\n",
    "stem2 = Stem4x4\n",
    "\n",
    "\n",
    "show_macs_params(stem1)\n",
    "inference_speed(stem1)\n",
    "print()\n",
    "show_macs_params(stem2)\n",
    "inference_speed(stem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepBasicUnit\t\tmacs=73960576.0\tparams=53952.0\n",
      "FLOPs= 0.073960576G\tparams= 0.053952M\n",
      "macs='73.961M'\tparams='53.952K'\n",
      "Mean@ 0.752ms Std@ 0.066ms FPS@ 1330.52\n"
     ]
    }
   ],
   "source": [
    "class RepBasicUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ca_type='ca'):\n",
    "        super(RepBasicUnit, self).__init__()\n",
    "        self.left_part = in_channels // 2\n",
    "        self.right_part_in = in_channels - self.left_part\n",
    "        self.right_part_out = out_channels - self.left_part\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            RepConv(self.right_part_in, self.right_part_out, kernel=1, activation=nn.ReLU6),\n",
    "            RepConv(self.right_part_out, self.right_part_out, kernel=3, padding=1,\n",
    "                    groups=self.right_part_out, activation=None),\n",
    "        )\n",
    "        if ca_type == 'se':\n",
    "            self.ca = SEBlock(out_channels, internal_neurons=out_channels // 16)\n",
    "        elif ca_type == 'ca':\n",
    "            self.ca = ChannelAttension(out_channels)\n",
    "        elif ca_type == 'none':\n",
    "            self.ca = nn.Identity()\n",
    "        else:\n",
    "            raise ValueError(f'<{ca_type=}> not in se|ca|none')\n",
    "\n",
    "    def forward(self, x):\n",
    "        left = x[:, :self.left_part, :, :]\n",
    "        right = x[:, self.left_part:, :, :]\n",
    "        out = self.conv(right)\n",
    "        out = self.ca(torch.cat((left, out), 1))\n",
    "        return out\n",
    "\n",
    "net = RepBasicUnit(256, 256)\n",
    "show_macs_params(net, dummy_input=torch.rand(1, 256, 64, 64))\n",
    "inference_speed(net, dummy_input=torch.rand(1, 256, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWConv_ELAN\t\tmacs=560988160.0\tparams=136960.0\n",
      "FLOPs= 0.56098816G\tparams= 0.13696M\n",
      "macs='560.988M'\tparams='136.960K'\n",
      "Mean@ 0.606ms Std@ 0.162ms FPS@ 1649.98\n"
     ]
    }
   ],
   "source": [
    "class DWConv_ELAN(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        mid_channel = in_channel // 2\n",
    "        self.conv1 = nn.Sequential(\n",
    "            RepConv(mid_channel, mid_channel, 3, 1, 1, groups=mid_channel, activation=None),\n",
    "            # RepConv(mid_channel, mid_channel, 1, 1, 0),\n",
    "            RepConv(mid_channel, mid_channel, 3, 1, 1, groups=mid_channel, activation=None),\n",
    "            # RepConv(mid_channel, mid_channel, 1, 1, 0),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            RepConv(mid_channel, mid_channel, 3, 1, 1, groups=mid_channel, activation=None),\n",
    "            # RepConv(mid_channel, mid_channel, 1, 1, 0),\n",
    "            RepConv(mid_channel, mid_channel, 3, 1, 1, groups=mid_channel, activation=None),\n",
    "            # RepConv(mid_channel, mid_channel, 1, 1, 0),\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(4 * mid_channel, out_channel, 1, 1, 0)\n",
    "        self.c = mid_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x[:, :self.c, :, :])\n",
    "        out2 = self.conv2(out1)\n",
    "        out = self.conv3(torch.cat([x, out1, out2], dim=1))\n",
    "        out = channel_shuffle(out, groups=2)\n",
    "        return out\n",
    "\n",
    "x = torch.rand(1, 256, 64, 64)\n",
    "net = DWConv_ELAN(256, 256)\n",
    "show_macs_params(net, dummy_input=x)\n",
    "inference_speed(net, dummy_input=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChannelAttension\t\tmacs=35712.0\tparams=35648.0\n",
      "FLOPs= 3.5712e-05G\tparams= 0.035648M\n",
      "macs='35.712K'\tparams='35.648K'\n",
      "Mean@ 0.316ms Std@ 0.082ms FPS@ 3160.25\n"
     ]
    }
   ],
   "source": [
    "net = ChannelAttension(256, deploy=True)\n",
    "x = torch.rand(1, 256, 32, 32)\n",
    "show_macs_params(net, dummy_input=x)\n",
    "inference_speed(net, dummy_input=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv\t\tmacs=67633152.0\tparams=65792.0\n",
      "FLOPs= 0.067633152G\tparams= 0.065792M\n",
      "macs='67.633M'\tparams='65.792K'\n",
      "Mean@ 0.107ms Std@ 0.078ms FPS@ 9369.75\n"
     ]
    }
   ],
   "source": [
    "net = RepConv(256, 256, 1, 1, 0, deploy=True)\n",
    "x = torch.rand(1, 256, 32, 32)\n",
    "show_macs_params(net, dummy_input=x)\n",
    "inference_speed(net, dummy_input=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRB\t\tmacs=294721792.0\tparams=143488.0\n",
      "FLOPs= 0.294721792G\tparams= 0.143488M\n",
      "macs='294.722M'\tparams='143.488K'\n",
      "Mean@ 1.481ms Std@ 0.108ms FPS@ 675.04\n"
     ]
    }
   ],
   "source": [
    "class MSRB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ca_type='none'):\n",
    "        super().__init__()\n",
    "        self.half_channels = in_channels // 2\n",
    "        self.branch1 = nn.ModuleList([\n",
    "            RepConv(self.half_channels, self.half_channels, 3, 1, 1,\n",
    "                    groups=self.half_channels, activation=None),\n",
    "            RepConv(self.half_channels, self.half_channels, 3, 1, 1,\n",
    "                    groups=self.half_channels, activation=None)\n",
    "             ])\n",
    "        self.branch2 = nn.ModuleList([\n",
    "            RepConv(self.half_channels, self.half_channels, 3, 1, 2, 2, \n",
    "                    groups=self.half_channels, activation=None),\n",
    "            RepConv(self.half_channels, self.half_channels, 3, 1, 2, 2,\n",
    "                    groups=self.half_channels, activation=None)\n",
    "            ])\n",
    "\n",
    "        # 信息交换，通道注意力模块\n",
    "        if ca_type == 'se':\n",
    "            self.ca = nn.ModuleList([\n",
    "                SEBlock(out_channels, internal_neurons=out_channels // 16),\n",
    "                SEBlock(out_channels, internal_neurons=out_channels // 16)])\n",
    "        elif ca_type == 'ca':\n",
    "            self.ca = nn.ModuleList([ChannelAttension(out_channels),\n",
    "                                     ChannelAttension(out_channels)])\n",
    "        else:\n",
    "            self.ca = nn.ModuleList([nn.Identity(), nn.Identity()])\n",
    "        \n",
    "        self.conv = RepConv(in_channels, out_channels, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for _b1, _b2, _ca in zip(self.branch1, self.branch2, self.ca):\n",
    "            left, right = torch.chunk(out, 2, dim=1)\n",
    "            left = _b1(left)\n",
    "            right = _b2(right)\n",
    "            out = out + _ca(torch.cat([left, right], dim=1))\n",
    "        return self.conv(out + x)\n",
    "\n",
    "net = MSRB(256, 256, 'ca')\n",
    "x = torch.rand(1, 256, 64, 64)\n",
    "show_macs_params(net, dummy_input=x)\n",
    "inference_speed(net, dummy_input=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试Hourglas_ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hourglass_ablation\t\tmacs=1136115584.0\tparams=2348693.0\n",
      "FLOPs= 1.136115584G\tparams= 2.348693M\n",
      "macs='1.136G'\tparams='2.349M'\n",
      "Mean@ 20.487ms Std@ 1.998ms FPS@ 48.81\n"
     ]
    }
   ],
   "source": [
    "from models import hourglass_ablation\n",
    "import addict\n",
    "cfg = dict(MODEL=dict(\n",
    "        name='hourglass_ablation',\n",
    "        input_channel=128,\n",
    "        output_channel=21,       # num_joints + 3 region map\n",
    "        num_stage=4,            # 每个沙漏模块不同尺度特征层个数\n",
    "        num_block=[2, 2, 2],\n",
    "        msrb=True,\n",
    "        rca=True,\n",
    "        ca_type='ca' ,\n",
    "))\n",
    "cfg = addict.Dict(cfg)\n",
    "net = hourglass_ablation(cfg)\n",
    "x = torch.rand(1, 3, 256, 256)\n",
    "show_macs_params(net, dummy_input=x)\n",
    "inference_speed(net, dummy_input=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('TorchCV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "435570d4219e70938454f0c8f629267d4bfa46e86b2ba3c4b1d73b5202317604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
