{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.training_kits import stdout_to_tqdm, load_pretrained_state\n",
    "\n",
    "from data import get_dataset\n",
    "from config import get_config\n",
    "from utils.visualization_tools import draw_heatmaps, draw_region_maps, draw_point, draw_bbox, draw_text,draw_centermap\n",
    "\n",
    "cfg, DATASET = get_config(\"config/freihand/cfg_freihand_hg_ms_att.py\")\n",
    "cfg['batch_size'] = 1\n",
    "cfg['workers'] = 1\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "new_size = cfg[\"image_size\"][0]\n",
    "def draw_region_bbox(img, xywhc, color=(0, 0, 255)):\n",
    "    cx, cy, w, h = xywhc[:4]\n",
    "    x1, y1, x2, y2 = cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2\n",
    "    x1 = int(max(0, x1))\n",
    "    y1 = int(max(0, y1))\n",
    "    x2 = int(min(x2, new_size))\n",
    "    y2 = int(min(y2, new_size))\n",
    "    img = draw_bbox(img, x1, y1, x2, y2, color=color)\n",
    "    return img\n",
    "\n",
    "def image_recovery(image):\n",
    "    if image.ndim == 4: \n",
    "        image = image[0]\n",
    "    image = image.permute(1, 2, 0).detach().numpy()\n",
    "    m = np.array([0.485, 0.456, 0.406])\n",
    "    s = np.array([0.229, 0.224, 0.225])\n",
    "    image = image * s + m\n",
    "    image *= 255\n",
    "    image = image.astype(np.uint8) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def make_heatmaps(image, heatmaps):\n",
    "    image = image_recovery(image)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    heatmaps = heatmaps.mul(255)\\\n",
    "                       .clamp(0, 255)\\\n",
    "                       .byte()\\\n",
    "                       .cpu().numpy()\n",
    "\n",
    "    num_joints, height, width = heatmaps.shape\n",
    "    image_resized = cv2.resize(image, (int(width), int(height)))\n",
    "\n",
    "    image_grid = np.zeros((height, (num_joints+1)*width, 3), dtype=np.uint8)\n",
    "\n",
    "    for j in range(num_joints):\n",
    "        # add_joints(image_resized, joints[:, j, :])\n",
    "        heatmap = heatmaps[j, :, :]\n",
    "        colored_heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        image_fused = colored_heatmap*0.7 + image_resized*0.3\n",
    "\n",
    "        width_begin = width * (j+1)\n",
    "        width_end = width * (j+2)\n",
    "        image_grid[:, width_begin:width_end, :] = image_fused\n",
    "\n",
    "    image_grid[:, 0:width, :] = image_resized\n",
    "\n",
    "    return image_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1、用于可视化用SimDR检测关键点的手部检测\n",
    "from models.center_simDR import LiteHourglassNet as Network\n",
    "from utils.result_parser import ResultParser\n",
    "\n",
    "img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = \\\n",
    "None, None, None, None, None, None, None, None\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, ground_truth=False, exp_name=''):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(cfg, DATASET, is_train=False, distributed=False)\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = Network().to(self.device)\n",
    "\n",
    "        self.ground_truth = ground_truth\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "            # self.model.load_state_dict(save_dict[\"state_dict\"])\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.writer = SummaryWriter(log_dir='jupyter_log/'+ exp_name)\n",
    "        self.parser = ResultParser()\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            for i, meta in enumerate(self.test_loader):\n",
    "                if i > n_img:\n",
    "                    break\n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "                img, target_x, target_y, target_weight, centermap, centermask, bbox, gt_kpts = meta\n",
    "                \n",
    "                if not self.ground_truth:\n",
    "                    pred_centermap, pred_x, pred_y = self.model(img.to(self.device))\n",
    "                else:\n",
    "                    pred_centermap, pred_x, pred_y = centermap, target_x, target_y\n",
    "         \n",
    "                # 结果解析，得到原图关键点和边界框\n",
    "                pred_kpts, pred_bboxes = self.parser.parse(pred_centermap, pred_x, pred_y)\n",
    "                ap50, ap = self.parser.evaluate_ap(pred_bboxes, bbox)\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    out_centermap = draw_centermap(centermap)\n",
    "                    out_centermap = [torch.tensor(out, dtype=torch.uint8) for out in out_centermap]\n",
    "                    imgs = torch.stack(out_centermap, dim=0)\n",
    "                    self.writer.add_image('centermap', imgs, i, dataformats='NHWC')\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    batch_xywh = pred_bboxes[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "\n",
    "                    for image, kpts, xywh in zip(img, pred_kpts, batch_xywh):  \n",
    "                    # for image, kpts, xywh in zip(img, gt_kpts, batch_xywh):    \n",
    "                        image = image.permute(1, 2, 0).detach().numpy()\n",
    "                        m = np.array([0.485, 0.456, 0.406])\n",
    "                        s = np.array([0.229, 0.224, 0.225])\n",
    "                        image = image * s + m\n",
    "                        image *= 255\n",
    "                        image = image.astype(np.uint8) \n",
    "                        \n",
    "                        # kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "                        kpts = kpts[0].detach().cpu().numpy()\n",
    "                        # print(f\"{image.shape=}\")\n",
    "                        print(f\"{bbox=}\")\n",
    "                        print(f\"{xywh=}\")\n",
    "                        print(f\"{i=} :{kpts=}\")\n",
    "                        print(F\"{i=} :{gt_kpts[0, 0]=}\")\n",
    "                        print('*'* 100)\n",
    "                        \n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                        image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "                        image_drawn = draw_region_bbox(image_drawn, xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(image_drawn, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_drawn, dtype=torch.uint8)], dim=0)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2、用于可视化用热图检测关键点的手部检测\n",
    "from utils.evaluation import evaluate_pck, evaluate_ap, get_coordinates_from_heatmap\n",
    "from utils.result_parser import ResultParser\n",
    "from models.pose_estimation import get_model\n",
    "import os\n",
    "\n",
    "class TestPreds:\n",
    "    def __init__(self, checkpoint=\"\", is_cuda=True, exp_name='cs', rm=False):\n",
    "\n",
    "        print(\"preparing data...\")\n",
    "        self.dataset, self.test_loader = get_dataset(cfg, DATASET,\n",
    "                                                     is_train=True,\n",
    "                                                     distributed=False)\n",
    "        print(\"done!\")\n",
    "\n",
    "        if is_cuda:\n",
    "            self.device = torch.device(0)\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        self.model = get_model(cfg).to(self.device)\n",
    "        \n",
    "        self.with_simdr = cfg['simdr_split_ratio'] > 0\n",
    "\n",
    "        if checkpoint != \"\":\n",
    "            print(\"loading state dict...\")\n",
    "            save_dict = torch.load(checkpoint, map_location=self.device)\n",
    "            print(f\"{save_dict.keys()=}\")\n",
    "            \n",
    "            state, is_match = load_pretrained_state(self.model.state_dict(),\n",
    "                                                    save_dict['state_dict'])\n",
    "\n",
    "            self.model.load_state_dict(state)\n",
    "            print(f\"done! {is_match=}\")\n",
    "        \n",
    "        self.result_parser = ResultParser(cfg)\n",
    "        \n",
    "        logdir = os.path.join('./jupyter_log', exp_name)\n",
    "        if rm and os.path.exists(logdir):\n",
    "            files = os.listdir(logdir)\n",
    "            files = [f for f in files if 'events' in files]\n",
    "            for file in files:\n",
    "                os.remove(os.path.join(logdir, file))\n",
    "                \n",
    "        self.writer = SummaryWriter(log_dir= logdir)\n",
    "\n",
    "    def test(self, n_img=10, show_hms=True, show_kpts=True, show_cd=False):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pck = 0\n",
    "            if n_img == -1:\n",
    "                n_img = len(self.test_loader)  # -1 整个数据集过一遍\n",
    "            \n",
    "            check_num = 0\n",
    "            for i, (img, targets, target_weight, bbox, gt_kpts, target_x, target_y) \\\n",
    "                in enumerate(self.test_loader):     \n",
    "                if i % 20 != 0:\n",
    "                    continue\n",
    "                \n",
    "                check_num +=1    \n",
    "                if check_num > n_img:\n",
    "                    break\n",
    "                    \n",
    "                start = cv2.getTickCount()  # 计时器起点\n",
    "\n",
    "                if show_cd:  # 显示循环检测的效果\n",
    "                    img, targets, gt_kpts, target_x, target_y = \\\n",
    "                        self.dataset.generate_cd_gt(img, gt_kpts, bbox, target_weight)\n",
    "                        \n",
    "                    bbox = torch.tensor([[[img.shape[3] / 2,\n",
    "                                           img.shape[2] / 2,\n",
    "                                           img.shape[3],\n",
    "                                           img.shape[2]]]], device=bbox.device)\n",
    "                \n",
    "                if self.with_simdr:\n",
    "                    output, pred_x, pred_y = self.model(img.to(self.device))\n",
    "                else:\n",
    "                    output = self.model(img.to(self.device))\n",
    "                    \n",
    "                region = output[-1][:, -3:]\n",
    "                hm_kpts = output[-1][:, :-3].to(self.device)\n",
    "\n",
    "                pck += evaluate_pck(hm_kpts, targets[-1][:, :-3], bbox, thr=0.2).item()\n",
    "                print(f\"{pck=}\")\n",
    "\n",
    "                # 画出热图\n",
    "                if show_hms:\n",
    "                    img_region = make_heatmaps(img, region[0])\n",
    "                    img_heatmap = make_heatmaps(img, hm_kpts[0])\n",
    "                    \n",
    "                    img_region  = torch.tensor(img_region, dtype=torch.uint8)\n",
    "                    self.writer.add_image('region', img_region , i, dataformats='HWC')\n",
    "                    \n",
    "                    img_heatmap  = torch.tensor(img_heatmap, dtype=torch.uint8)\n",
    "                    self.writer.add_image('heatmap', img_heatmap , i, dataformats='HWC')\n",
    "\n",
    "                # 画出关键点\n",
    "                if show_kpts:\n",
    "                    _, _, batch_xywh = evaluate_ap(region, bbox, new_size, k=10, iou_thr=0.3)\n",
    "                    batch_xywh = batch_xywh[0]\n",
    "                    if batch_xywh is None:\n",
    "                        print(\"没有找到目标框\")\n",
    "                        batch_xywh = [[4, 4, 2, 2, 0]]\n",
    "                        \n",
    "                    # ! 因为现在是单手，所以特殊处理一下\n",
    "                    bbox = bbox[0]\n",
    "                    gt_kpts = gt_kpts[:, 0]\n",
    "\n",
    "                    first_time_kpt = self.result_parser.get_pred_kpt(hm_kpts, resized=True)\n",
    "                    pred_bboxes = self.result_parser.get_pred_bbox(region)\n",
    "                    second_time_kpt = self.result_parser.get_group_keypoints(self.model, img, pred_bboxes, hm_kpts)\n",
    "\n",
    "                    for image, gk, ftk, stk, xywh, gt_xywh in zip(img, gt_kpts,\n",
    "                                                          first_time_kpt, second_time_kpt,\n",
    "                                                          batch_xywh, bbox):    \n",
    "                        image = image_recovery(image)\n",
    "                        image_gt = draw_results(image, gk, gt_xywh, gt_xywh)\n",
    "                        img_first_pred = draw_results(image, ftk, xywh, gt_xywh)\n",
    "                        img_scecond_pred = draw_results(image, stk, xywh, gt_xywh)\n",
    "\n",
    "                    end = cv2.getTickCount()  # 计时器终点\n",
    "                    fps = round(cv2.getTickFrequency() / (end - start))\n",
    "                    text = str(fps) + \"fps\"\n",
    "                    img = draw_text(img_first_pred, text, (15, 15, 20, 20))\n",
    "                    # img = img[:,:,::-1]   # BGR to RGB\n",
    "                    imgs = torch.stack([torch.tensor(image, dtype=torch.uint8),\n",
    "                                        torch.tensor(image_gt, dtype=torch.uint8),\n",
    "                                        torch.tensor(img_first_pred, dtype=torch.uint8),\n",
    "                                        torch.tensor(img_scecond_pred, dtype=torch.uint8),\n",
    "                                        ], dim=0)\n",
    "                    # img_grid = vutils.make_grid(imgs, normalize=True, scale_each=True, nrow=2)\n",
    "                    self.writer.add_images('images', imgs, i, dataformats='NHWC')\n",
    "                    \n",
    "            pck = pck / (n_img+1)\n",
    "            print(f\"{n_img=}\")\n",
    "            print(f\"{pck=}\")\n",
    "            self.writer.close()\n",
    "\n",
    "def draw_results(image, kpts, xywh, gt_xywh):\n",
    "    \"\"\"在图片上画出预测关键点、预测框和真值框\n",
    "\n",
    "    Args:\n",
    "        image (numpy): (h, w, c)\n",
    "        kpts (tensor): (1, n_joints, 3)\n",
    "        xywh (tensor): (5,) (cx, cy, w, h, score)\n",
    "        gt_xywh (tensor): (4,) (cx, cy, w, h)\n",
    "    \"\"\"\n",
    "    kpts = kpts.squeeze(dim=0).detach().cpu().numpy()\n",
    "    image_drawn = draw_point(img=image.copy(), keypoints=kpts)\n",
    "    image_drawn = draw_region_bbox(image_drawn, xywh, (255, 0, 0))\n",
    "    image_drawn = draw_region_bbox(image_drawn, gt_xywh, (0, 255, 0))\n",
    "    return image_drawn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data...\n",
      "sample number of training dataset:  104192\n",
      "done!\n",
      "loading state dict...\n",
      "save_dict.keys()=dict_keys(['epoch', 'PCK', 'AP', 'AP50', 'state_dict', 'optimizer', 'config'])\n",
      "done! is_match=True\n",
      "pck=1.0\n",
      "pck=1.0\n",
      "pck=1.9047619104385376\n",
      "pck=2.0000000074505806\n",
      "pck=2.0000000074505806\n",
      "pck=2.0000000074505806\n",
      "pck=2.5238095596432686\n",
      "pck=2.5238095596432686\n",
      "pck=2.5238095596432686\n",
      "pck=2.952380992472172\n",
      "pck=3.9047619476914406\n",
      "pck=3.9047619476914406\n",
      "pck=4.238095290958881\n",
      "pck=4.238095290958881\n",
      "pck=5.238095290958881\n",
      "pck=5.238095290958881\n",
      "pck=5.238095290958881\n",
      "pck=6.19047624617815\n",
      "pck=7.19047624617815\n",
      "pck=8.19047624617815\n",
      "pck=8.285714343190193\n",
      "pck=9.285714343190193\n",
      "pck=9.285714343190193\n",
      "pck=9.333333391696215\n",
      "pck=9.666666734963655\n",
      "pck=9.761904831975698\n",
      "pck=10.761904831975698\n",
      "pck=10.761904831975698\n",
      "pck=11.047619130462408\n",
      "pck=11.333333428949118\n",
      "pck=12.238095339387655\n",
      "pck=12.333333436399698\n",
      "pck=13.285714391618967\n",
      "pck=14.238095346838236\n",
      "pck=14.238095346838236\n",
      "pck=15.238095346838236\n",
      "pck=16.095238212496042\n",
      "pck=16.61904776468873\n",
      "pck=16.857143003493547\n",
      "pck=17.809523958712816\n",
      "pck=17.809523958712816\n",
      "pck=17.809523958712816\n",
      "pck=17.809523958712816\n",
      "pck=17.809523958712816\n",
      "pck=18.61904777958989\n",
      "pck=18.809523973613977\n",
      "pck=19.14285731688142\n",
      "pck=20.14285731688142\n",
      "pck=20.14285731688142\n",
      "pck=21.14285731688142\n",
      "pck=21.380952555686235\n",
      "pck=22.380952555686235\n",
      "pck=23.380952555686235\n",
      "pck=24.380952555686235\n",
      "pck=24.85714303329587\n",
      "pck=24.85714303329587\n",
      "pck=24.85714303329587\n",
      "pck=24.85714303329587\n",
      "pck=25.14285733178258\n",
      "pck=25.619047809392214\n",
      "pck=25.619047809392214\n",
      "pck=25.619047809392214\n",
      "pck=25.952381152659655\n",
      "pck=26.238095451146364\n",
      "pck=27.238095451146364\n",
      "pck=27.238095451146364\n",
      "pck=28.238095451146364\n",
      "pck=28.238095451146364\n",
      "pck=28.571428794413805\n",
      "pck=28.809524033218622\n",
      "pck=29.809524033218622\n",
      "pck=29.809524033218622\n",
      "pck=30.523809764534235\n",
      "pck=31.523809764534235\n",
      "pck=32.476190719753504\n",
      "pck=32.476190719753504\n",
      "pck=32.476190719753504\n",
      "pck=32.476190719753504\n",
      "pck=32.61904786899686\n",
      "pck=33.61904786899686\n",
      "pck=34.61904786899686\n",
      "pck=35.09523834660649\n",
      "pck=35.33333358541131\n",
      "pck=36.33333358541131\n",
      "pck=37.33333358541131\n",
      "pck=38.33333358541131\n",
      "pck=38.33333358541131\n",
      "pck=39.33333358541131\n",
      "pck=39.33333358541131\n",
      "pck=39.33333358541131\n",
      "pck=40.28571454063058\n",
      "pck=40.428571689873934\n",
      "pck=41.428571689873934\n",
      "pck=41.428571689873934\n",
      "pck=41.428571689873934\n",
      "pck=42.428571689873934\n",
      "pck=43.19047646597028\n",
      "pck=43.19047646597028\n",
      "pck=43.28571456298232\n",
      "pck=43.28571456298232\n",
      "pck=44.28571456298232\n",
      "pck=44.28571456298232\n",
      "pck=45.28571456298232\n",
      "pck=46.28571456298232\n",
      "pck=46.28571456298232\n",
      "pck=46.57142886146903\n",
      "pck=47.57142886146903\n",
      "pck=48.380952682346106\n",
      "pck=49.14285745844245\n",
      "pck=49.19047650694847\n",
      "pck=50.19047650694847\n",
      "pck=50.47619080543518\n",
      "pck=51.14285749197006\n",
      "pck=52.14285749197006\n",
      "pck=52.14285749197006\n",
      "pck=52.4761908352375\n",
      "pck=53.4761908352375\n",
      "pck=53.809524178504944\n",
      "pck=54.809524178504944\n",
      "pck=55.809524178504944\n",
      "pck=56.809524178504944\n",
      "pck=57.809524178504944\n",
      "pck=57.809524178504944\n",
      "pck=58.809524178504944\n",
      "pck=59.809524178504944\n",
      "pck=59.809524178504944\n",
      "pck=60.809524178504944\n",
      "pck=61.809524178504944\n",
      "pck=62.809524178504944\n",
      "pck=63.76190513372421\n",
      "pck=63.76190513372421\n",
      "pck=64.4285718202591\n",
      "pck=65.4285718202591\n",
      "pck=66.4285718202591\n",
      "pck=67.4285718202591\n",
      "pck=67.4285718202591\n",
      "pck=68.38095277547836\n",
      "pck=69.38095277547836\n",
      "pck=69.38095277547836\n",
      "pck=70.38095277547836\n",
      "pck=71.04761946201324\n",
      "pck=71.04761946201324\n",
      "pck=71.23809565603733\n",
      "pck=72.23809565603733\n",
      "pck=73.23809565603733\n",
      "pck=74.00000043213367\n",
      "pck=75.00000043213367\n",
      "pck=75.28571473062038\n",
      "pck=75.90476237237453\n",
      "pck=76.90476237237453\n",
      "pck=77.90476237237453\n",
      "pck=77.90476237237453\n",
      "pck=78.33333380520344\n",
      "pck=78.33333380520344\n",
      "pck=79.14285762608051\n",
      "pck=79.76190526783466\n",
      "pck=80.71428622305393\n",
      "pck=81.71428622305393\n",
      "pck=82.71428622305393\n",
      "pck=83.71428622305393\n",
      "pck=84.71428622305393\n",
      "pck=84.71428622305393\n",
      "pck=85.71428622305393\n",
      "pck=86.71428622305393\n",
      "pck=86.71428622305393\n",
      "pck=87.71428622305393\n",
      "pck=88.6666671782732\n",
      "pck=88.6666671782732\n",
      "pck=89.6666671782732\n",
      "pck=90.61904813349247\n",
      "pck=91.61904813349247\n",
      "pck=92.61904813349247\n",
      "pck=93.61904813349247\n",
      "pck=94.61904813349247\n",
      "pck=94.61904813349247\n",
      "pck=95.19047673046589\n",
      "pck=96.19047673046589\n",
      "pck=97.19047673046589\n",
      "pck=98.19047673046589\n",
      "pck=99.19047673046589\n",
      "pck=100.09523864090443\n",
      "pck=100.28571483492851\n",
      "pck=101.28571483492851\n",
      "pck=101.28571483492851\n",
      "pck=101.61904817819595\n",
      "pck=101.61904817819595\n",
      "pck=102.42857199907303\n",
      "pck=103.42857199907303\n",
      "pck=104.42857199907303\n",
      "pck=105.28571486473083\n",
      "pck=105.666667252779\n",
      "pck=106.666667252779\n",
      "pck=107.666667252779\n",
      "pck=107.666667252779\n",
      "pck=107.666667252779\n",
      "pck=108.42857202887535\n",
      "pck=109.1904768049717\n",
      "pck=110.09523871541023\n",
      "pck=111.09523871541023\n",
      "pck=111.09523871541023\n",
      "pck=112.09523871541023\n",
      "pck=112.09523871541023\n",
      "pck=113.09523871541023\n",
      "pck=113.09523871541023\n",
      "pck=113.76190540194511\n",
      "pck=114.76190540194511\n",
      "pck=115.47619113326073\n",
      "pck=116.47619113326073\n",
      "pck=116.47619113326073\n",
      "pck=117.47619113326073\n",
      "pck=118.47619113326073\n",
      "pck=119.47619113326073\n",
      "pck=120.42857208848\n",
      "pck=121.42857208848\n",
      "pck=121.47619113698602\n",
      "pck=121.47619113698602\n",
      "pck=122.38095304742455\n",
      "pck=122.38095304742455\n",
      "pck=122.95238164439797\n",
      "pck=123.95238164439797\n",
      "pck=123.95238164439797\n",
      "pck=124.000000692904\n",
      "pck=124.14285784214735\n",
      "pck=125.14285784214735\n",
      "pck=125.14285784214735\n",
      "pck=126.09523879736662\n",
      "pck=126.6190483495593\n",
      "pck=127.52381025999784\n",
      "pck=128.33333408087492\n",
      "pck=129.33333408087492\n",
      "pck=129.33333408087492\n",
      "pck=130.33333408087492\n",
      "pck=130.57142931967974\n",
      "pck=130.57142931967974\n",
      "pck=130.57142931967974\n",
      "pck=130.57142931967974\n",
      "pck=131.57142931967974\n",
      "pck=131.57142931967974\n",
      "pck=132.57142931967974\n",
      "pck=133.04761979728937\n",
      "pck=133.04761979728937\n",
      "pck=133.80952457338572\n",
      "pck=134.80952457338572\n",
      "pck=135.66666743904352\n",
      "pck=136.57142934948206\n",
      "pck=136.57142934948206\n",
      "pck=136.95238173753023\n",
      "pck=136.95238173753023\n",
      "pck=137.14285793155432\n",
      "pck=137.42857223004103\n",
      "pck=138.42857223004103\n",
      "pck=138.42857223004103\n",
      "pck=138.42857223004103\n",
      "pck=138.42857223004103\n",
      "pck=139.42857223004103\n",
      "pck=139.42857223004103\n",
      "pck=139.42857223004103\n",
      "pck=140.42857223004103\n",
      "pck=140.42857223004103\n",
      "pck=140.42857223004103\n",
      "pck=141.42857223004103\n",
      "pck=141.95238178223372\n",
      "pck=142.71428655833006\n",
      "pck=142.71428655833006\n",
      "pck=143.66666751354933\n",
      "pck=143.66666751354933\n",
      "pck=144.66666751354933\n",
      "pck=144.66666751354933\n",
      "pck=144.90476275235415\n",
      "pck=145.90476275235415\n",
      "pck=146.90476275235415\n",
      "pck=147.8571437075734\n",
      "pck=148.8571437075734\n",
      "pck=149.8571437075734\n",
      "pck=150.8571437075734\n",
      "pck=151.80952466279268\n",
      "pck=151.80952466279268\n",
      "pck=152.76190561801195\n",
      "pck=153.76190561801195\n",
      "pck=153.76190561801195\n",
      "pck=154.57142943888903\n",
      "pck=155.57142943888903\n",
      "pck=156.57142943888903\n",
      "pck=156.80952467769384\n",
      "pck=157.19047706574202\n",
      "pck=158.19047706574202\n",
      "pck=158.61904849857092\n",
      "pck=159.0000008866191\n",
      "pck=159.2380961254239\n",
      "pck=160.2380961254239\n",
      "pck=161.14285803586245\n",
      "pck=161.14285803586245\n",
      "pck=161.95238185673952\n",
      "pck=161.95238185673952\n",
      "pck=162.95238185673952\n",
      "pck=163.95238185673952\n",
      "pck=163.95238185673952\n",
      "pck=164.95238185673952\n",
      "pck=165.95238185673952\n",
      "pck=166.85714376717806\n",
      "n_img=300\n",
      "pck=0.5543426703228507\n"
     ]
    }
   ],
   "source": [
    "# path = \"./checkpoint/MSRB-D-DW-PELEE/1HG-ME-att-c256/2021-12-27/0.981_PCK_47epoch.pt\"\n",
    "path = \"output/freihand/steplr/freihand_plus_hg_ms_att/2022-03-20/best_pck.pt\"\n",
    "t = TestPreds(checkpoint=path, is_cuda=False, exp_name='freihand_plus/test', rm=True)\n",
    "t.test(n_img=300, show_hms=True, show_kpts=True, show_cd=False)\n",
    "# tensorboard --samples_per_plugin scalars=100,images=100 --logdir \"./jupyter_log/<exp_name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('TorchCV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "435570d4219e70938454f0c8f629267d4bfa46e86b2ba3c4b1d73b5202317604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
