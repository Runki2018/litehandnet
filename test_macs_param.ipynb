{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "%matplotlib inline\n",
    "from thop import profile\n",
    "\n",
    "def show_macs_params(net, a):\n",
    "    macs, params = profile(net, inputs=(a,), verbose=False)  # macs == FLOPS, GFLOPS == 1e12 * FLOPS\n",
    "    print(f\"{net._get_name()}\\t\\t{macs=}\\t{params=}\")\n",
    "    from thop import clever_format\n",
    "    macs, params = clever_format([macs, params], \"%.3f\")\n",
    "    print(f\"{macs=}\\t{params=}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.shape=torch.Size([1, 128, 8, 8])\n",
      "h.shape=torch.Size([1, 128, 16, 16])\n",
      "h.shape=torch.Size([1, 128, 32, 32])\n",
      "h.shape=torch.Size([1, 128, 64, 64])\n",
      "MultiScaleAttentionHourglass\t\tmacs=1169090432.0\tparams=2312728.0\n",
      "macs='1.169G'\tparams='2.313M'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import MultiScaleAttentionHourglass\n",
    "net = MultiScaleAttentionHourglass(4, 128, 24, [3, 5, 2])\n",
    "x = torch.rand(1, 3, 256, 256)\n",
    "show_macs_params(net, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRHandNet\t\tmacs=12144135680.0\tparams=18255032.0\n",
      "macs='12.144G'\tparams='18.255M'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import srhandnet\n",
    "device = torch.device('cpu')\n",
    "net = srhandnet(None).to(device)\n",
    "x = torch.rand(1, 3, 256, 256)\n",
    "# y = net(x)\n",
    "show_macs_params(net, x)\n",
    "# y[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/data/miniconda3/envs/TorchCV/lib/python3.8/site-packages/thop/vision/basic_hooks.py:92: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  kernel = torch.DoubleTensor([*(x[0].shape[2:])]) // torch.DoubleTensor(list((m.output_size,))).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiteHRNet\t\tmacs=559691660.0\tparams=1773484.0\n",
      "macs='559.692M'\tparams='1.773M'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import litehrnet\n",
    "# from models.lite_hrnet import LiteHRNet as Network\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# state = torch.load('checkpoint/Center_SimDR/1HG-ME-att-c128-k2/73.82_AP_0epoch.pt', map_location=device)['state_dict']\n",
    "# total_params = sum([v.nelement() for v in state.values()])\n",
    "# print(\"Number of parameter: %.2fM\" % (total_params / 1e6))\n",
    "\n",
    "# for k, v in state.items():\n",
    "#     print(f\"{k}:\\t {v.shape}\")\n",
    "\n",
    "a = torch.rand(1, 3, 256, 256)\n",
    "net = litehrnet().to(device)\n",
    "# 通过 thop 计算\n",
    "show_macs_params(net, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "class SimDR(nn.Module):\n",
    "\n",
    "    def __init__(self) :\n",
    "        super(SimDR, self).__init__()\n",
    "        \n",
    "        self.pred_x = nn.Linear(size ** 2 , int(256 * 2)) \n",
    "        self.pred_y = nn.Linear(size ** 2, int(256 * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # kpts = self.vector_feature(feature)\n",
    "        # kpts = rearrange(kpts, 'b c h w -> b c (h w)')\n",
    "        b,c, h, w = x.shape\n",
    "        x = x.view(b, c, -1)\n",
    "        pred_x = self.pred_x(x)  # (b, c, w * k)\n",
    "        pred_y = self.pred_y(x)  # (b, c, h * k)\n",
    "        return pred_x, pred_y  \n",
    "\n",
    "from thop import profile\n",
    "from models.layers import LiteHG, LiteResidual, Residual, LiteBRC, InvertedResidual, GhostConv, DWConv, SplitDWConv, channel_attention3x3, GhostConv, ReducedConv1x1, ms_att, fuse_block\n",
    "from models.LiteHourglass import BRC, StemBlock, LiteHourglass\n",
    "from models.attention import NAM_Channel_Att\n",
    "from models.hourglass_SA import ME_att, HourglassNet_SA, my_pelee_stem\n",
    "\n",
    "print('successfully import package')\n",
    "\n",
    "a = torch.rand(1, 21, size, size)\n",
    "show_macs_params(SimDR(), a)\n",
    "\n",
    "a = torch.rand(1, 3, 256, 256)\n",
    "show_macs_params(StemBlock(64, 32), a)\n",
    "\n",
    "\n",
    "size = 32\n",
    "c = 128\n",
    "a = torch.rand(1, c, size, size)\n",
    "\n",
    "# net = NAM_Channel_Att(c)\n",
    "# net = channel_attention3x3(c)\n",
    "# net = InvertedResidual(c, c, 2)\n",
    "show_macs_params(DWConv(c, c), a)\n",
    "# net = GhostConv(c, c)\n",
    "show_macs_params(SplitDWConv(c, c), a)\n",
    "show_macs_params(channel_attention3x3(c), a)\n",
    "\n",
    "# show_macs_params(LiteHG(4, c), a)\n",
    "# net = Bi_HG(4, c)\n",
    "# net = BRC(c, c)\n",
    "# net = GhostConv(c, c)\n",
    "# net = ReducedConv1x1(c, c)\n",
    "\n",
    "show_macs_params(ME_att(c, c), a)\n",
    "# net = ms_att(c)\n",
    "\n",
    "\n",
    "# net = MS_HG(c, c * 4, 4, 4)\n",
    "# net = LiteResidual(c, c)\n",
    "# show_macs_params(net, a)\n",
    "\n",
    "# net = LiteBRC(c, c)\n",
    "\n",
    "# net = ME_att(c, c)\n",
    "\n",
    "show_macs_params(BRC(c, c), a)\n",
    "show_macs_params(Residual(c, c), a)\n",
    "# # y = net(a)\n",
    "\n",
    "print(f\"完整网络的参数：\")\n",
    "a = torch.rand(1, 3, 128, 128)\n",
    "# net = my_pelee_stem(128)\n",
    "# net = LiteHourglass(1, 128)\n",
    "net = HourglassNet_SA(1)\n",
    "show_macs_params(net, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Module):\n",
    "    def __init__(self, inp_dim=128) :\n",
    "        super().__init__() \n",
    "        self.pre = nn.Sequential(\n",
    "            # Conv(3, 64, 7, 2, bn=True, relu=True),\n",
    "            nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Residual(64, 128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            Residual(128, 128),\n",
    "            Residual(128, inp_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.pre(x)\n",
    "\n",
    "a = torch.rand(1, 3, 256, 256)\n",
    "net = Stem()\n",
    "show_macs_params(net, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class channel_attention3x3(nn.Module):\n",
    "    def __init__(self, channel=128):\n",
    "        super().__init__()\n",
    "        self.att = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                    nn.BatchNorm2d(channel),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(channel, channel, 1, 1, 0, groups=channel),      \n",
    "                    # nn.Dropout(p=0.3),\n",
    "                    nn.Flatten(),\n",
    "                    # nn.Linear(channel, channel),\n",
    "                    nn.Sigmoid(),  \n",
    "                    # nn.BatchNorm1d(channel),\n",
    "                    # nn.LeakyReLU(inplace=True),  \n",
    "                    )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        att = self.att(x)\n",
    "        b, c, _, _ = x.shape\n",
    "        x = x * att.view(b, c, 1, 1)\n",
    "        return x\n",
    "\n",
    "a = torch.rand(1, 128, 64, 64)\n",
    "net = channel_attention3x3()\n",
    "show_macs_params(net, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3499/1556096336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# a = F.upsample_nearest(a, scale_factor=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "a = torch.rand(1, 2, 5, 5)\n",
    "# a = F.upsample_nearest(a, scale_factor=2)\n",
    "a= F.interpolate(a, scale_factor=2, mode='nearest')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0045, 0.0062, 0.0032],\n",
       "        [0.0041, 0.0055, 0.0034]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "softmax = nn.Softmax(dim=2)\n",
    "LogSoftmax = nn.LogSoftmax(dim=2)  # [B,LOGITS]\n",
    "criterion_ = nn.KLDivLoss(reduction='none')\n",
    "\n",
    "hm_preds = torch.rand(2, 3, 4, 4)\n",
    "hm_gts = torch.rand(2, 3, 4, 4)\n",
    "\n",
    "b, c, h, w = hm_preds.shape\n",
    "log_scores = LogSoftmax(hm_preds.view(b, c, -1))\n",
    "gt_scorces = softmax(hm_gts.view(b, c, -1))\n",
    "loss = torch.mean(criterion_(log_scores, gt_scorces), dim=2)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0424, 0.1075, 0.0152],\n",
       "        [0.6122, 0.4424, 0.1948]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "a.mul(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "435570d4219e70938454f0c8f629267d4bfa46e86b2ba3c4b1d73b5202317604"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('TorchCV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
